{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09ad9650",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataloading as dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f49db68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepforest import utilities\n",
    "import rasterio as rio\n",
    "import os \n",
    "import glob\n",
    "import geopandas as gpd\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib.patches as patches\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import Compose, ToTensor\n",
    "import torchvision\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import ast\n",
    "from comet_ml import Experiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "071b05d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report multiple hyperparameters using a dictionary:\n",
    "hyper_params = {\n",
    "   \"learning_rate\": 0.001,\n",
    "   \"num_epochs\": 10,\n",
    "   \"batch_size\": 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f88ffc18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: sklearn, torch. Metrics and hyperparameters can still be logged using comet_ml.log_metrics() and comet_ml.log_parameters()\n",
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET WARNING: Unknown error exporting current conda environment\n",
      "COMET WARNING: Unknown error exporting current conda environment\n",
      "COMET WARNING: Unknown error retrieving Conda package as an explicit file\n",
      "COMET WARNING: Unknown error retrieving Conda information\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.com/zhou-m/macrosystems-multitask/23a96b85be3042edbf111d3106473065\n",
      "\n"
     ]
    }
   ],
   "source": [
    "experiment = Experiment(\n",
    "  api_key=\"xuGNxq43n5AvOfi7zn0JavYDR\",\n",
    "  project_name=\"macrosystems-multitask\",\n",
    "  workspace=\"zhou-m\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41a4741f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = 'C:/Users/zhou.m/Documents/2023_Fall/NeonTree/weecology/evaluation/RGB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f463b37",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m device\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eae4e0a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_path</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018_SJER_3_252000_4104000_image_628.tif</th>\n",
       "      <td>[29, 362, 325, 334, 174, 230, 265, 153]</td>\n",
       "      <td>[1, 206, 2, 60, 6, 56, 167, 63]</td>\n",
       "      <td>[94, 400, 378, 390, 211, 254, 333, 209]</td>\n",
       "      <td>[31, 299, 62, 122, 50, 84, 232, 126]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018_SJER_3_252000_4106000_image_234.tif</th>\n",
       "      <td>[92]</td>\n",
       "      <td>[158]</td>\n",
       "      <td>[174]</td>\n",
       "      <td>[233]</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018_SJER_3_252000_4106000_image_326.tif</th>\n",
       "      <td>[138, 20, 138]</td>\n",
       "      <td>[265, 54, 27]</td>\n",
       "      <td>[178, 66, 247]</td>\n",
       "      <td>[297, 105, 149]</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018_SJER_3_252000_4106000_image_66.tif</th>\n",
       "      <td>[67, 99]</td>\n",
       "      <td>[372, 298]</td>\n",
       "      <td>[102, 206]</td>\n",
       "      <td>[400, 399]</td>\n",
       "      <td>[1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018_SJER_3_252000_4107000_image_372.tif</th>\n",
       "      <td>[298, 211]</td>\n",
       "      <td>[309, 142]</td>\n",
       "      <td>[400, 324]</td>\n",
       "      <td>[400, 254]</td>\n",
       "      <td>[1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WREF_070_2019.tif</th>\n",
       "      <td>[259, 360, 379, 217, 231, 246, 49, 361, 223, 2...</td>\n",
       "      <td>[50, 79, 73, 56, 49, 50, 58, 12, 9, 9, 51, 104...</td>\n",
       "      <td>[271, 378, 400, 231, 242, 258, 69, 394, 260, 2...</td>\n",
       "      <td>[69, 105, 101, 70, 63, 64, 81, 43, 43, 35, 82,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WREF_072_2019.tif</th>\n",
       "      <td>[343, 284, 338, 331, 215, 276, 191, 1, 105, 31...</td>\n",
       "      <td>[142, 1, 81, 3, 300, 185, 362, 243, 64, 342, 3...</td>\n",
       "      <td>[400, 331, 400, 400, 302, 386, 261, 67, 158, 3...</td>\n",
       "      <td>[193, 51, 143, 77, 377, 299, 400, 348, 114, 40...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WREF_075_2019.tif</th>\n",
       "      <td>[314, 199, 314, 251, 336, 374, 301, 40, 286, 1...</td>\n",
       "      <td>[267, 271, 150, 177, 1, 98, 1, 65, 165, 197, 1...</td>\n",
       "      <td>[341, 235, 358, 299, 364, 400, 332, 71, 311, 2...</td>\n",
       "      <td>[297, 313, 203, 238, 30, 129, 25, 103, 198, 25...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WREF_083_2019.tif</th>\n",
       "      <td>[373, 130, 1, 294, 369, 2, 20, 183, 339, 206, ...</td>\n",
       "      <td>[231, 369, 366, 344, 38, 189, 90, 1, 331, 154,...</td>\n",
       "      <td>[400, 189, 17, 341, 400, 50, 78, 258, 400, 275...</td>\n",
       "      <td>[258, 400, 399, 396, 104, 234, 165, 32, 400, 2...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WREF_084_2019.tif</th>\n",
       "      <td>[15, 28, 163, 74, 362, 218, 44, 75, 132, 170, ...</td>\n",
       "      <td>[120, 161, 1, 215, 343, 308, 268, 149, 350, 27...</td>\n",
       "      <td>[34, 76, 230, 107, 400, 256, 83, 113, 195, 220...</td>\n",
       "      <td>[138, 204, 47, 250, 400, 353, 322, 187, 400, 3...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>194 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                       xmin  \\\n",
       "image_path                                                                                    \n",
       "2018_SJER_3_252000_4104000_image_628.tif            [29, 362, 325, 334, 174, 230, 265, 153]   \n",
       "2018_SJER_3_252000_4106000_image_234.tif                                               [92]   \n",
       "2018_SJER_3_252000_4106000_image_326.tif                                     [138, 20, 138]   \n",
       "2018_SJER_3_252000_4106000_image_66.tif                                            [67, 99]   \n",
       "2018_SJER_3_252000_4107000_image_372.tif                                         [298, 211]   \n",
       "...                                                                                     ...   \n",
       "WREF_070_2019.tif                         [259, 360, 379, 217, 231, 246, 49, 361, 223, 2...   \n",
       "WREF_072_2019.tif                         [343, 284, 338, 331, 215, 276, 191, 1, 105, 31...   \n",
       "WREF_075_2019.tif                         [314, 199, 314, 251, 336, 374, 301, 40, 286, 1...   \n",
       "WREF_083_2019.tif                         [373, 130, 1, 294, 369, 2, 20, 183, 339, 206, ...   \n",
       "WREF_084_2019.tif                         [15, 28, 163, 74, 362, 218, 44, 75, 132, 170, ...   \n",
       "\n",
       "                                                                                       ymin  \\\n",
       "image_path                                                                                    \n",
       "2018_SJER_3_252000_4104000_image_628.tif                    [1, 206, 2, 60, 6, 56, 167, 63]   \n",
       "2018_SJER_3_252000_4106000_image_234.tif                                              [158]   \n",
       "2018_SJER_3_252000_4106000_image_326.tif                                      [265, 54, 27]   \n",
       "2018_SJER_3_252000_4106000_image_66.tif                                          [372, 298]   \n",
       "2018_SJER_3_252000_4107000_image_372.tif                                         [309, 142]   \n",
       "...                                                                                     ...   \n",
       "WREF_070_2019.tif                         [50, 79, 73, 56, 49, 50, 58, 12, 9, 9, 51, 104...   \n",
       "WREF_072_2019.tif                         [142, 1, 81, 3, 300, 185, 362, 243, 64, 342, 3...   \n",
       "WREF_075_2019.tif                         [267, 271, 150, 177, 1, 98, 1, 65, 165, 197, 1...   \n",
       "WREF_083_2019.tif                         [231, 369, 366, 344, 38, 189, 90, 1, 331, 154,...   \n",
       "WREF_084_2019.tif                         [120, 161, 1, 215, 343, 308, 268, 149, 350, 27...   \n",
       "\n",
       "                                                                                       xmax  \\\n",
       "image_path                                                                                    \n",
       "2018_SJER_3_252000_4104000_image_628.tif            [94, 400, 378, 390, 211, 254, 333, 209]   \n",
       "2018_SJER_3_252000_4106000_image_234.tif                                              [174]   \n",
       "2018_SJER_3_252000_4106000_image_326.tif                                     [178, 66, 247]   \n",
       "2018_SJER_3_252000_4106000_image_66.tif                                          [102, 206]   \n",
       "2018_SJER_3_252000_4107000_image_372.tif                                         [400, 324]   \n",
       "...                                                                                     ...   \n",
       "WREF_070_2019.tif                         [271, 378, 400, 231, 242, 258, 69, 394, 260, 2...   \n",
       "WREF_072_2019.tif                         [400, 331, 400, 400, 302, 386, 261, 67, 158, 3...   \n",
       "WREF_075_2019.tif                         [341, 235, 358, 299, 364, 400, 332, 71, 311, 2...   \n",
       "WREF_083_2019.tif                         [400, 189, 17, 341, 400, 50, 78, 258, 400, 275...   \n",
       "WREF_084_2019.tif                         [34, 76, 230, 107, 400, 256, 83, 113, 195, 220...   \n",
       "\n",
       "                                                                                       ymax  \\\n",
       "image_path                                                                                    \n",
       "2018_SJER_3_252000_4104000_image_628.tif               [31, 299, 62, 122, 50, 84, 232, 126]   \n",
       "2018_SJER_3_252000_4106000_image_234.tif                                              [233]   \n",
       "2018_SJER_3_252000_4106000_image_326.tif                                    [297, 105, 149]   \n",
       "2018_SJER_3_252000_4106000_image_66.tif                                          [400, 399]   \n",
       "2018_SJER_3_252000_4107000_image_372.tif                                         [400, 254]   \n",
       "...                                                                                     ...   \n",
       "WREF_070_2019.tif                         [69, 105, 101, 70, 63, 64, 81, 43, 43, 35, 82,...   \n",
       "WREF_072_2019.tif                         [193, 51, 143, 77, 377, 299, 400, 348, 114, 40...   \n",
       "WREF_075_2019.tif                         [297, 313, 203, 238, 30, 129, 25, 103, 198, 25...   \n",
       "WREF_083_2019.tif                         [258, 400, 399, 396, 104, 234, 165, 32, 400, 2...   \n",
       "WREF_084_2019.tif                         [138, 204, 47, 250, 400, 353, 322, 187, 400, 3...   \n",
       "\n",
       "                                                                                      label  \n",
       "image_path                                                                                   \n",
       "2018_SJER_3_252000_4104000_image_628.tif                           [1, 1, 1, 1, 1, 1, 1, 1]  \n",
       "2018_SJER_3_252000_4106000_image_234.tif                                                [1]  \n",
       "2018_SJER_3_252000_4106000_image_326.tif                                          [1, 1, 1]  \n",
       "2018_SJER_3_252000_4106000_image_66.tif                                              [1, 1]  \n",
       "2018_SJER_3_252000_4107000_image_372.tif                                             [1, 1]  \n",
       "...                                                                                     ...  \n",
       "WREF_070_2019.tif                         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "WREF_072_2019.tif                         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "WREF_075_2019.tif                         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "WREF_083_2019.tif                         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "WREF_084_2019.tif                         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "\n",
       "[194 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df = pd.read_csv('annotations_filtered.csv', index_col = 0)\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10c3f676",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get unique image paths\n",
    "unique_image_paths = filtered_df.index\n",
    "\n",
    "# Split the unique image paths into training and testing sets\n",
    "train_image_paths, test_image_paths = train_test_split(unique_image_paths, test_size=0.2, random_state=42)\n",
    "\n",
    "# Filter the DataFrame based on the selected image paths for training and testing\n",
    "train_df = filtered_df.loc[train_image_paths]\n",
    "test_df = filtered_df.loc[test_image_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "499435b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Compose([ToTensor()])\n",
    "train_dataset = dl.TreeBoundingBoxes(train_df, image_dir, transform)\n",
    "test_dataset = dl.TreeBoundingBoxes(test_df, image_dir, transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c82285d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FasterRCNN(\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
       "  )\n",
       "  (backbone): BackboneWithFPN(\n",
       "    (body): IntermediateLayerGetter(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): FrozenBatchNorm2d(64, eps=1e-05)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=1e-05)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=1e-05)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=1e-05)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=1e-05)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=1e-05)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=1e-05)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=1e-05)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=1e-05)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=1e-05)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=1e-05)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=1e-05)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=1e-05)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=1e-05)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=1e-05)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(1024, eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(2048, eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fpn): FeaturePyramidNetwork(\n",
       "      (inner_blocks): ModuleList(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (layer_blocks): ModuleList(\n",
       "        (0-3): 4 x Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (extra_blocks): LastLevelMaxPool()\n",
       "    )\n",
       "  )\n",
       "  (rpn): RegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): RoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
       "    (box_head): TwoMLPHead(\n",
       "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
       "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pre-trained Faster R-CNN model\n",
    "model = fasterrcnn_resnet50_fpn()\n",
    "\n",
    "# Modify the classification head for the number of classes in your dataset\n",
    "num_classes = 2 \n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(\n",
    "    in_features, num_classes\n",
    ")\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a1c196e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, dataloader, epoch, experiment):\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for images, targets in train_loader:\n",
    "        images = images.permute(0,2,1,3)\n",
    "        images = [image.to(device) for image in images]\n",
    "\n",
    "        reshaped_boxes = targets['boxes'][0].to(torch.float).to(device)\n",
    "        reshaped_labels = torch.clone(targets['labels'][0]).to(device)\n",
    "\n",
    "        # Combine into the required target format\n",
    "        targets = [{'boxes': reshaped_boxes, 'labels': reshaped_labels}]\n",
    "\n",
    "        # Forward pass\n",
    "        loss_dict = model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        epoch_loss += losses.item()\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Update learning rate\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "    # Log epoch_loss to Comet; step is each batch\n",
    "    experiment.log_metric(\"epoch_loss\", epoch_loss, epoch=epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6199c365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model\n",
      "Epoch: 0/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Comet.ml Experiment Summary\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.com/zhou-m/macrosystems-multitask/23a96b85be3042edbf111d3106473065\n",
      "COMET INFO:   Metrics [count] (min, max):\n",
      "COMET INFO:     train_epoch_loss [11] : (24.554077558219433, 41.45701373368502)\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     environment details : 1\n",
      "COMET INFO:     filename            : 1\n",
      "COMET INFO:     git metadata        : 1\n",
      "COMET INFO:     installed packages  : 1\n",
      "COMET INFO:     notebook            : 1\n",
      "COMET INFO:     source_code         : 1\n",
      "COMET INFO: ---------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 7240.40 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: sklearn, torch. Metrics and hyperparameters can still be logged using comet_ml.log_metrics() and comet_ml.log_parameters()\n",
      "COMET INFO: Uploading metrics, params, and assets to Comet before program termination (may take several seconds)\n",
      "COMET INFO: The Python SDK has 3600 seconds to finish before aborting...\n"
     ]
    }
   ],
   "source": [
    "# Define the optimizer and learning rate scheduler\n",
    "learning_rate = hyper_params['learning_rate']\n",
    "num_epochs = hyper_params['num_epochs']\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0.0005)\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "# Training loop\n",
    "print('Training Model')\n",
    "\n",
    "\n",
    "with experiment.train():\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(num_epochs + 1):\n",
    "            train(model, optimizer, train_loader, epoch, experiment)\n",
    "            \n",
    "            #if epoch % 99 == 0:\n",
    "            print(\"Epoch: {}/{}\".format(epoch, num_epochs))\n",
    "                \n",
    "    end_time = time.time()\n",
    "    print(f'Time: {end_time - start_time:.2f} sec')\n",
    "    \n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'trained_model.pth')\n",
    "\n",
    "experiment.end()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bc",
   "language": "python",
   "name": "bc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
